{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNpGV9zjKT1pi8FjFp1K8A+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sangh0/DeepLearning-Tutorial/blob/main/current_materials/8_implement_vgg_network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# VGG Network 논문 읽고 따라 구현하기\n",
        "\n",
        "- 이번 챕터에서는 논문을 읽고 따라 구현하는 방법을 배울 거예요\n",
        "- VGG network 논문은 ImageNet Challenge에서 2위를 차지한 유명한 모델이예요\n",
        "- 이때 1위는 GoogLeNet이었지만 오히려 VGGNet이 더 주목을 받았는데, 그 이유는 매우 단순한 구조를 가졌다는 점이예요"
      ],
      "metadata": {
        "id": "cTWNxKh-qcLB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 먼저, VGGNet의 구조는 다음과 같아요\n",
        "\n",
        "<img src = \"https://greeksharifa.github.io/public/img/2021-10-24-ImageNet-CNN-models/VGGNet.png\">\n",
        "\n",
        "\n",
        "- 그림으로 표현하면 다음과 같고요\n",
        "\n",
        "<img src = \"https://www.researchgate.net/publication/355049790/figure/fig2/AS:1075420338348033@1633411597542/The-structure-of-VGG16-modelThis-figure-was-created-with-Image-onlineco-and-exported.png\">"
      ],
      "metadata": {
        "id": "_0SZpomsruLU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35p9ocU8qWnD",
        "outputId": "47c20fe7-064b-4fbf-c23c-863d60bf003b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 224, 224]           1,792\n",
            "              ReLU-2         [-1, 64, 224, 224]               0\n",
            "            Conv2d-3         [-1, 64, 224, 224]          36,928\n",
            "              ReLU-4         [-1, 64, 224, 224]               0\n",
            "         MaxPool2d-5         [-1, 64, 112, 112]               0\n",
            "            Conv2d-6        [-1, 128, 112, 112]          73,856\n",
            "              ReLU-7        [-1, 128, 112, 112]               0\n",
            "            Conv2d-8        [-1, 128, 112, 112]         147,584\n",
            "              ReLU-9        [-1, 128, 112, 112]               0\n",
            "        MaxPool2d-10          [-1, 128, 56, 56]               0\n",
            "           Conv2d-11          [-1, 256, 56, 56]         295,168\n",
            "             ReLU-12          [-1, 256, 56, 56]               0\n",
            "           Conv2d-13          [-1, 256, 56, 56]         590,080\n",
            "             ReLU-14          [-1, 256, 56, 56]               0\n",
            "           Conv2d-15          [-1, 256, 56, 56]         590,080\n",
            "             ReLU-16          [-1, 256, 56, 56]               0\n",
            "        MaxPool2d-17          [-1, 256, 28, 28]               0\n",
            "           Conv2d-18          [-1, 512, 28, 28]       1,180,160\n",
            "             ReLU-19          [-1, 512, 28, 28]               0\n",
            "           Conv2d-20          [-1, 512, 28, 28]       2,359,808\n",
            "             ReLU-21          [-1, 512, 28, 28]               0\n",
            "           Conv2d-22          [-1, 512, 28, 28]       2,359,808\n",
            "             ReLU-23          [-1, 512, 28, 28]               0\n",
            "        MaxPool2d-24          [-1, 512, 14, 14]               0\n",
            "           Conv2d-25          [-1, 512, 14, 14]       2,359,808\n",
            "             ReLU-26          [-1, 512, 14, 14]               0\n",
            "           Conv2d-27          [-1, 512, 14, 14]       2,359,808\n",
            "             ReLU-28          [-1, 512, 14, 14]               0\n",
            "           Conv2d-29          [-1, 512, 14, 14]       2,359,808\n",
            "             ReLU-30          [-1, 512, 14, 14]               0\n",
            "        MaxPool2d-31            [-1, 512, 7, 7]               0\n",
            "           Linear-32                 [-1, 4096]     102,764,544\n",
            "             ReLU-33                 [-1, 4096]               0\n",
            "           Linear-34                 [-1, 4096]      16,781,312\n",
            "             ReLU-35                 [-1, 4096]               0\n",
            "           Linear-36                 [-1, 1000]       4,097,000\n",
            "================================================================\n",
            "Total params: 138,357,544\n",
            "Trainable params: 138,357,544\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 218.53\n",
            "Params size (MB): 527.79\n",
            "Estimated Total Size (MB): 746.89\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision.models import vgg16_bn, VGG16_BN_Weights\n",
        "\n",
        "\n",
        "# Direct Implementation\n",
        "class VGG16(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(VGG16, self).__init__()\n",
        "        # build VGG16\n",
        "        self.features = nn.Sequential(\n",
        "            # first conv block --------------------------------------------------------\n",
        "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            # -------------------------------------------------------------------------\n",
        "\n",
        "            # second conv block -------------------------------------------------------\n",
        "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            # -------------------------------------------------------------------------\n",
        "\n",
        "            # third conv block --------------------------------------------------------\n",
        "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            # --------------------------------------------------------------------------\n",
        "\n",
        "            # fourth conv block --------------------------------------------------------\n",
        "            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            # --------------------------------------------------------------------------\n",
        "\n",
        "            # fifth conv block ---------------------------------------------------------\n",
        "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            # --------------------------------------------------------------------------\n",
        "        )\n",
        "\n",
        "        # fully connected layers -------------------------------------------------------\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(7*7*512, 4096),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4096, 1000),\n",
        "        )\n",
        "        # ------------------------------------------------------------------------------\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.size(0)\n",
        "        x = self.features(x)\n",
        "        x = x.view(batch_size, -1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "from torchsummary import summary\n",
        "\n",
        "summary(VGG16(), (3, 224, 224))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What is Pre-trained weight?\n",
        "- 이렇게 VGG16을 직접 구현하고 모델의 파라미터 갯수도 똑같은 걸 확인했어요\n",
        "- 하지만 직접 구현할 경우 가장 큰 단점은 pre-trained weight가 없다는 것이예요\n",
        "- 왜 pre-trained weight가 중요한지 비유를 들어드릴게요\n",
        "- 갓난 아이와 고등학교 수학 과정을 마친 성인이 있다고 가정하죠\n",
        "- 이 두 사람에게 대학 미적분 과목을 시험을 보게 할 겁니다\n",
        "- 자, 여기서 우리는 대충 갓난 아이보단 성인이 더 시험을 잘 볼 것이라 예측을 할 수 있죠\n",
        "- 그 이유는 당연히 초, 중, 고 수학 교육과정을 거치면서 어느 정도 수학의 개념을 배웠다는 것 때문이죠\n",
        "- 이것을 pre-trained weight를 가지고 있는 모델이라고 생각하시면 됩니다\n",
        "- 반면, 갓난 아이는 random weight를 가지고 있다고 생각하시면 돼요\n",
        "- 즉, pre-trained weight로 초기화하여 모델 학습을 하면 random weight로 할 때보다 더 빠르게 학습을 할 수 있고 그 리소스 또한 줄어들 것이라고 예측할 수 있어요\n",
        "\n",
        "### Pre-trained weight 사용법\n",
        "- 1. PyTorch에서 제공해주는 기본 모델 사용\n",
        "    - 가장 보편적인 방법이예요\n",
        "    - PyTorch에는 유명한 모델들에 한해 구현이 되어 있고 역시 benchmark 데이터셋으로 학습한 pre-trained weight가 존재해요\n",
        "\n",
        "- 2. 오픈소스에서 제공해주는 모델 사용\n",
        "    - 이것 역시 위의 방법과 비슷하게 보편적인 방법이예요\n",
        "    - 다양한 연구원과 개발자들이 오픈소스로 공개한 레퍼지토리를 통해 pre-trained weight를 받을 수 있어요\n",
        "\n",
        "- 3. 직접 구축\n",
        "    - 가장 무식하고 시간과 비용이 많이 드는 방법이예요\n",
        "    - 말 그대로 직접 모델 만들고 직접 사전 학습을 하는 거예요"
      ],
      "metadata": {
        "id": "TnNzKFhLu0_o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pytorch vgg16 로드하기\n",
        "model = vgg16_bn(weights=VGG16_BN_Weights.IMAGENET1K_V1)\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--24PDuKsTl2",
        "outputId": "4296995f-5fda-4be4-948e-6c7543f8d704"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg16_bn-6c64b313.pth\" to /root/.cache/torch/hub/checkpoints/vgg16_bn-6c64b313.pth\n",
            "100%|██████████| 528M/528M [00:09<00:00, 59.6MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VGG(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (9): ReLU(inplace=True)\n",
              "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (12): ReLU(inplace=True)\n",
              "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (16): ReLU(inplace=True)\n",
              "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (19): ReLU(inplace=True)\n",
              "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (22): ReLU(inplace=True)\n",
              "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (26): ReLU(inplace=True)\n",
              "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (29): ReLU(inplace=True)\n",
              "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (32): ReLU(inplace=True)\n",
              "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (36): ReLU(inplace=True)\n",
              "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (39): ReLU(inplace=True)\n",
              "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (42): ReLU(inplace=True)\n",
              "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Dropout(p=0.5, inplace=False)\n",
              "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): Dropout(p=0.5, inplace=False)\n",
              "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "위 코드의 문제점은 마지막 레이어 노드 수가 1,000개인 것을 알 수 있어요\n",
        "즉, ImageNet dataset의 클래스 수는 1,000개라 맞춰져 있어요\n",
        "\n",
        "여기서 만약에 내가 가지고 있는 데이터셋의 수가 10개라면 코드를 수정해야 돼요\n",
        "다음과 같이 수정하면 돼요\n",
        "\"\"\"\n",
        "\n",
        "class VGG16(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(VGG16, self).__init__()\n",
        "        model = vgg16_bn(weights=VGG16_BN_Weights.IMAGENET1K_V1)\n",
        "\n",
        "        self.features = model.features\n",
        "        self.avgpool = model.avgpool\n",
        "        self.classifier = model.classifier\n",
        "        self.classifier[-1] = nn.Linear(4096, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "summary(VGG16(), (3, 224, 224))"
      ],
      "metadata": {
        "id": "rendqtN30Y-x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5375f55c-78e1-4d1a-d458-b3a192ad0b36"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 224, 224]           1,792\n",
            "       BatchNorm2d-2         [-1, 64, 224, 224]             128\n",
            "              ReLU-3         [-1, 64, 224, 224]               0\n",
            "            Conv2d-4         [-1, 64, 224, 224]          36,928\n",
            "       BatchNorm2d-5         [-1, 64, 224, 224]             128\n",
            "              ReLU-6         [-1, 64, 224, 224]               0\n",
            "         MaxPool2d-7         [-1, 64, 112, 112]               0\n",
            "            Conv2d-8        [-1, 128, 112, 112]          73,856\n",
            "       BatchNorm2d-9        [-1, 128, 112, 112]             256\n",
            "             ReLU-10        [-1, 128, 112, 112]               0\n",
            "           Conv2d-11        [-1, 128, 112, 112]         147,584\n",
            "      BatchNorm2d-12        [-1, 128, 112, 112]             256\n",
            "             ReLU-13        [-1, 128, 112, 112]               0\n",
            "        MaxPool2d-14          [-1, 128, 56, 56]               0\n",
            "           Conv2d-15          [-1, 256, 56, 56]         295,168\n",
            "      BatchNorm2d-16          [-1, 256, 56, 56]             512\n",
            "             ReLU-17          [-1, 256, 56, 56]               0\n",
            "           Conv2d-18          [-1, 256, 56, 56]         590,080\n",
            "      BatchNorm2d-19          [-1, 256, 56, 56]             512\n",
            "             ReLU-20          [-1, 256, 56, 56]               0\n",
            "           Conv2d-21          [-1, 256, 56, 56]         590,080\n",
            "      BatchNorm2d-22          [-1, 256, 56, 56]             512\n",
            "             ReLU-23          [-1, 256, 56, 56]               0\n",
            "        MaxPool2d-24          [-1, 256, 28, 28]               0\n",
            "           Conv2d-25          [-1, 512, 28, 28]       1,180,160\n",
            "      BatchNorm2d-26          [-1, 512, 28, 28]           1,024\n",
            "             ReLU-27          [-1, 512, 28, 28]               0\n",
            "           Conv2d-28          [-1, 512, 28, 28]       2,359,808\n",
            "      BatchNorm2d-29          [-1, 512, 28, 28]           1,024\n",
            "             ReLU-30          [-1, 512, 28, 28]               0\n",
            "           Conv2d-31          [-1, 512, 28, 28]       2,359,808\n",
            "      BatchNorm2d-32          [-1, 512, 28, 28]           1,024\n",
            "             ReLU-33          [-1, 512, 28, 28]               0\n",
            "        MaxPool2d-34          [-1, 512, 14, 14]               0\n",
            "           Conv2d-35          [-1, 512, 14, 14]       2,359,808\n",
            "      BatchNorm2d-36          [-1, 512, 14, 14]           1,024\n",
            "             ReLU-37          [-1, 512, 14, 14]               0\n",
            "           Conv2d-38          [-1, 512, 14, 14]       2,359,808\n",
            "      BatchNorm2d-39          [-1, 512, 14, 14]           1,024\n",
            "             ReLU-40          [-1, 512, 14, 14]               0\n",
            "           Conv2d-41          [-1, 512, 14, 14]       2,359,808\n",
            "      BatchNorm2d-42          [-1, 512, 14, 14]           1,024\n",
            "             ReLU-43          [-1, 512, 14, 14]               0\n",
            "        MaxPool2d-44            [-1, 512, 7, 7]               0\n",
            "AdaptiveAvgPool2d-45            [-1, 512, 7, 7]               0\n",
            "           Linear-46                 [-1, 4096]     102,764,544\n",
            "             ReLU-47                 [-1, 4096]               0\n",
            "          Dropout-48                 [-1, 4096]               0\n",
            "           Linear-49                 [-1, 4096]      16,781,312\n",
            "             ReLU-50                 [-1, 4096]               0\n",
            "          Dropout-51                 [-1, 4096]               0\n",
            "           Linear-52                   [-1, 10]          40,970\n",
            "================================================================\n",
            "Total params: 134,309,962\n",
            "Trainable params: 134,309,962\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 322.13\n",
            "Params size (MB): 512.35\n",
            "Estimated Total Size (MB): 835.06\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 여기까지 VGG16을 구현하는 코드에 대해 살펴봤어요\n",
        "- 이제 딥러닝 분야 전체적인 overview에 대해서 간단하게 얘기해볼게요"
      ],
      "metadata": {
        "id": "GJSoyEwc1xOc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Overview\n",
        "**Data Type**\n",
        "- AI 분야에서는 크게 3개 유형의 데이터셋이 존재해요\n",
        "- Image, Text, Audio, Tabular\n",
        "- 이미지, 텍스트, 오디오는 굉장히 복잡도가 높은 편에 속하는 데이터라 주로 비선형 학습에 유리한 딥러닝 모델을 많이 사용해요\n",
        "- 반면, Tabular는 잘 정리가 되어있고 전처리를 잘만 하면 간단한 머신러닝 알고리즘으로도 잘 학습할 수 있어요\n",
        "\n",
        "**Vision AI**\n",
        "- 이미지부터 살펴볼게요\n",
        "- AI에 이미지 데이터를 적용한 task는 굉장히 많아요\n",
        "- 크게 Classification, Object Detection, Semantic Segmentation 3개의 task가 존재해요\n",
        "- Classification은 말 그대로 이미지가 주어지면 해당 이미지의 클래스가 무엇인지 예측하는 작업이예요\n",
        "- Object Detection은 분류를 넘어서 객체의 위치까지 파악하는 작업이예요\n",
        "\n",
        "<img src = \"https://kajabi-storefronts-production.kajabi-cdn.com/kajabi-storefronts-production/file-uploads/blogs/22606/images/1446e76-f181-6047-4e73-8d8ba3c6a50e_object_detection_1.webp\">\n",
        "\n",
        "- Detection은 위의 사진처럼 사진이 주어지면 사람, 자동차, 신호등, 간판 등을 찾아 box를 그려주고 그 객체의 클래스까지 분류해줘요\n",
        "- 주로 Faster R-CNN, YOLO 등의 알고리즘이 유명해요\n",
        "\n",
        "- Semantic Segmentation은 픽셀 단위로 분류를 하는 작업이예요\n",
        "\n",
        "<img src = \"https://miro.medium.com/v2/resize:fit:1400/1*KICInky28yGdU9T45kIL5Q.jpeg\">\n",
        "\n",
        "- 위 이미지처럼 사람, 자동차, 도로, 나무, 건물 등에 해당하는 객체를 픽셀 단위로 분류해줘요\n",
        "\n",
        "- 이 외에도 Pose Estimation\n",
        "\n",
        "<img src = \"https://miro.medium.com/v2/resize:fit:975/1*DTaPdSzIw4rMmD-6hO15rQ.png\">\n",
        "\n",
        "- Image Generation\n",
        "\n",
        "<img src = \"https://rameenabdal.github.io/StyleFlow/assets/teaser.png\">\n",
        "\n",
        "- 이렇게 Vision AI에 다양한 분야가 존재해요\n",
        "\n",
        "\n",
        "**Text**\n",
        "- Natural Language Process 즉, NLP라고도 불리는 task예요\n",
        "- 불과 GPT가 등장하기 전까지만 해도 NLP는 Question Answering, Text classification, Translation, NER, Text summarization 등의 task가 존재했어요\n",
        "- 하지만 지금, LLM이 등장한 이후로는 위 세부적인 task들이 필요가 없을 정도로 LLM 하나만으로도 광범위한 task들을 다루기 쉬워졌죠\n",
        "\n",
        "**Audio**\n",
        "- Audio도 마찬가지로 Speech Recognition,\n",
        "Emotion Recognition, Audio Classification 등의 task가 존재해요\n"
      ],
      "metadata": {
        "id": "M3WJoy2Y1xQ_"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Y3ribGWN1Bl8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}