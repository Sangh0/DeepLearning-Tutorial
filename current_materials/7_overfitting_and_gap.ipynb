{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP1qkZqu2kyjJ7LnSsJObXN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sangh0/DeepLearning-Tutorial/blob/main/current_materials/7_overfitting_and_gap.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 이번 챕터에서는 over-fitting 해결 방법과 Global Average Pooling에 대해서 살펴볼게요\n",
        "\n",
        "# Over-fitting (과적합)을 해결하는 방법\n",
        "\n",
        "- 이번 강의에서는 Over-fitting 문제를 해결하는 방법에 대해서 살펴볼게요\n",
        "- 먼저, Over-fitting이란 training data에 대해서 성능이 좋은 반면, 그 외의 데이터에는 낮은 성능을 가지는 현상을 의미해요\n",
        "- 그림으로 살펴볼까요\n",
        "\n",
        "<img src = \"https://pozalabs.github.io/assets/images/Regularization/overfitting.png\">\n",
        "\n",
        "- 우리가 모델을 학습할 때 의도하는 방향성은 데이터 포인트 하나하나 모두 다 맞추는 것이 아니라 경향성만을 파악하는 것이예요\n",
        "- 즉, 모델의 일반화된 성능을 얻어 어떤 데이터가 들어가든 잘 예측할 수 있도록 학습해야 하죠\n",
        "- over-fitting 문제를 해결할 수 있는 가장 효과적인 방법은 데이터를 더 많이 확보하는 거예요\n",
        "- 근데 데이터를 확보하는 것이 어려운 task가 존재해서 over-fitting을 피하기 위한 다양한 방법론들이 연구되었어요\n",
        "\n",
        "- 1. Early Stopping\n",
        "    - validation의 loss가 증가하기 시작하는 지점 전까지 model을 저장해 학습을 종료해 over fitting이 일어나지 않도록 설정\n",
        "    \n",
        "    <img src = \"https://production-media.paperswithcode.com/methods/Screen_Shot_2020-05-28_at_12.59.56_PM_1D7lrVF.png\" width=500>\n",
        "\n",
        "- 2. Regularization or Weight Decay\n",
        "    - Network의 특정 weight가 너무 커지는 것이 over fitting을 유도할 수 있으므로 weight에 규제를 걸어줌\n",
        "    - L1 regularization, L2 regularization이 존재\n",
        "    - L1 regularization은 $Loss = \\mathcal{L}(y_{pred}, y_{label}) + \\lambda \\sum_i^N \\vert w_i \\vert$\n",
        "    - L2 regularization은 $Loss = \\mathcal{L}(y_{pred}, y_{label}) + \\lambda \\sum_i^N w_i ^2$\n",
        "    - L1 regularization\n",
        "        - 위 식을 미분하면 $\\frac{\\partial}{\\partial w}Loss = \\frac{\\partial}{\\partial w}\\mathcal{L} + \\lambda \\sum_i^N sign(w_i)$이라 할 수 있음\n",
        "        - 즉, 가중치의 크기가 아니라 오직 부호에만 의존함\n",
        "        - 또한 중요하지 않은 weight는 0으로 만들어줌 (다른 말로 모델이 결과 예측에 불필요하다고 판단되는 피쳐를 제거하는 기능도 수행)\n",
        "    - L2 regularization\n",
        "        - 위 식을 미분하면 $\\frac{\\partial}{\\partial w}Loss = \\frac{\\partial}{\\partial w}\\mathcal{L} + \\lambda \\sum_i^N 2w_i$이라 할 수 있음\n",
        "        - 즉, weight의 크기에 비례해 큰 값을 가지는 weight는 더 크게 감소되는 기능을 수행\n",
        "        - 다시 말해, weight의 급격한 변화를 방지하고 모델이 더 안정적으로 학습할 수 있도록 도움을 줌\n",
        "\n",
        "3. Batch Normalization\n",
        "    - batch normalization은 feature 값들을 정규화\n",
        "    - feature 값들이 치우치는 것을 방지하기 위해 평균 0, 분산 1로 만들어줌\n",
        "\n",
        "    <img src = \"https://velog.velcdn.com/images/js03210/post/e01fd3cd-0ae4-4a9f-8701-12a0e30e7056/image.png\">\n",
        "\n",
        "4. Dropout\n",
        "    - Dropout은 학습 중 일부 노드에 대해서는 동작하지 않도록 설정하는 방법\n",
        "    - 즉, 일부 노드에 대해 weight 업데이트를 시키지 않음\n",
        "    - 매 iteration마다 dropout이 random하게 동작해 model ensemble 효과를 가짐\n",
        "    - 또한 학습 데이터의 모든 샘플에 대해 같은 노드를 사용하지 않아 모델이 특정 샘플에 대해 지나치게 최적화되는 것을 방지함으로써 over-fitting을 막을 수 있음\n",
        "\n",
        "    <img src = \"https://kh-kim.github.io/nlp_with_deep_learning_blog/assets/images/1-14/04-dropout_overview.png\" width=600>\n",
        "\n",
        "$$a$$"
      ],
      "metadata": {
        "id": "2C-u4vexoPSx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qaLDesS3oFQ0"
      },
      "outputs": [],
      "source": [
        "import numpy as np # 텐서 계산을 위해\n",
        "import matplotlib.pyplot as plt # 시각화를 위해\n",
        "\n",
        "import torch # 파이토치 텐서 사용을 위해\n",
        "import torch.nn as nn # 뉴럴 네트워크 빌드를 위해\n",
        "import torch.optim as optim # optimizer 사용을 위해\n",
        "import torchvision.datasets as dsets # torchvision에 내장된 MNIST 데이터셋 다운로드 위해\n",
        "import torchvision.transforms as transforms # torchvision 전처리를 위해\n",
        "from torch.utils.data import DataLoader # 딥러닝 학습 데이터로더 구현을 위해"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set hyperparameters\n",
        "Config = {\n",
        "    'batch_size': 32,\n",
        "    'learning_rate': 0.01,\n",
        "    'epochs': 10,\n",
        "}"
      ],
      "metadata": {
        "id": "yoFSVuYPMnQw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load MNIST dataset\n",
        "train_set = dsets.MNIST(\n",
        "    root='mnist/',\n",
        "    train=True,\n",
        "    transform=transforms.ToTensor(),\n",
        "    download=True,\n",
        ")\n",
        "\n",
        "valid_set = dsets.MNIST(\n",
        "    root='mnist/',\n",
        "    train=False,\n",
        "    transform=transforms.ToTensor(),\n",
        "    download=True,\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    dataset=train_set,\n",
        "    batch_size=Config['batch_size'],\n",
        "    shuffle=True,\n",
        "    drop_last=True,\n",
        ")\n",
        "\n",
        "valid_loader = DataLoader(\n",
        "    dataset=valid_set,\n",
        "    batch_size=Config['batch_size'],\n",
        "    shuffle=True,\n",
        "    drop_last=True,\n",
        ")"
      ],
      "metadata": {
        "id": "vp7Mqx1LMpQ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "\n",
        "    def __init__(self, in_dim=1, hidden_dim=8, out_dim=10):\n",
        "        super(CNN, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            # convolution layer\n",
        "            nn.Conv2d(in_dim, hidden_dim, kernel_size=3, stride=1, padding=1),\n",
        "            # batch normalization layer\n",
        "            nn.BatchNorm2d(hidden_dim),\n",
        "            # activation layer\n",
        "            nn.ReLU(),\n",
        "            # dropout layer\n",
        "            nn.Dropout(0.1),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(hidden_dim, hidden_dim*2, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(hidden_dim*2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(7 * 7 * hidden_dim*2, 100),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(100, out_dim),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.size(0)\n",
        "        x = self.features(x)\n",
        "        x = x.view(batch_size, -1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "from torchsummary import summary\n",
        "\n",
        "summary(CNN(), (1, 28, 28))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bwcr2y0vMrO1",
        "outputId": "066e8ebd-2131-4c39-eaaf-20d36c88275a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1            [-1, 8, 28, 28]              80\n",
            "       BatchNorm2d-2            [-1, 8, 28, 28]              16\n",
            "              ReLU-3            [-1, 8, 28, 28]               0\n",
            "           Dropout-4            [-1, 8, 28, 28]               0\n",
            "         MaxPool2d-5            [-1, 8, 14, 14]               0\n",
            "            Conv2d-6           [-1, 16, 14, 14]           1,168\n",
            "       BatchNorm2d-7           [-1, 16, 14, 14]              32\n",
            "              ReLU-8           [-1, 16, 14, 14]               0\n",
            "           Dropout-9           [-1, 16, 14, 14]               0\n",
            "        MaxPool2d-10             [-1, 16, 7, 7]               0\n",
            "           Linear-11                  [-1, 100]          78,500\n",
            "             ReLU-12                  [-1, 100]               0\n",
            "           Linear-13                   [-1, 10]           1,010\n",
            "================================================================\n",
            "Total params: 80,806\n",
            "Trainable params: 80,806\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.31\n",
            "Params size (MB): 0.31\n",
            "Estimated Total Size (MB): 0.62\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# over-fitting을 유도하기 위해 모델을 복잡하게 빌드\n",
        "model = CNN(in_dim=1, hidden_dim=16, out_dim=10).to(device)\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=Config['learning_rate'])\n",
        "\n",
        "def cal_accuracy(outputs, labels):\n",
        "    outputs = torch.argmax(outputs, dim=1)\n",
        "    correct = (outputs == labels).sum()/len(outputs)\n",
        "    return correct\n",
        "\n",
        "\n",
        "train_loss_list, train_acc_list = [], []\n",
        "valid_loss_list, valid_acc_list = [], []\n",
        "\n",
        "for epoch in range(Config['epochs']):\n",
        "    # Training phase ----------------------------------------------------------\n",
        "    model.train()\n",
        "    train_loss, train_acc = 0, 0\n",
        "    for batch, (images, labels) in enumerate(train_loader):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        acc = cal_accuracy(outputs, labels)\n",
        "        train_acc += acc.item()\n",
        "        train_acc_list.append(acc.item())\n",
        "        loss = loss_func(outputs, labels)\n",
        "        train_loss += loss.item()\n",
        "        train_loss_list.append(loss.item())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "    print(f\"# Epoch: {epoch+1}/{Config['epochs']}\")\n",
        "    print(f\"# Training phase {'-' * 50}\")\n",
        "    print(f'loss: {train_loss/(batch+1):.3f}, accuracy: {train_acc/(batch+1):.3f}')\n",
        "    print(f\"{'-' * 70}\")\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    # Validation phase --------------------------------------------------------\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        valid_loss, valid_acc = 0, 0\n",
        "        for batch, (images, labels) in enumerate(valid_loader):\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            acc = cal_accuracy(outputs, labels)\n",
        "            valid_acc += acc.item()\n",
        "            valid_acc_list.append(acc.item())\n",
        "            loss = loss_func(outputs, labels)\n",
        "            valid_loss += loss.item()\n",
        "            valid_loss_list.append(loss.item())\n",
        "\n",
        "    print(f\"# Validation phase {'-' * 50}\")\n",
        "    print(f'loss: {valid_loss/(batch+1):.3f}, accuracy: {valid_acc/(batch+1):.3f}')\n",
        "    print(f\"{'-' * 70}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kh1ijitaM0Pt",
        "outputId": "372257fc-6083-42f1-f5ae-bb35c34e5eae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# Epoch: 1/10\n",
            "# Training phase --------------------------------------------------\n",
            "loss: 0.139, accuracy: 0.958\n",
            "----------------------------------------------------------------------\n",
            "# Validation phase --------------------------------------------------\n",
            "loss: 0.077, accuracy: 0.977\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "# Epoch: 2/10\n",
            "# Training phase --------------------------------------------------\n",
            "loss: 0.080, accuracy: 0.977\n",
            "----------------------------------------------------------------------\n",
            "# Validation phase --------------------------------------------------\n",
            "loss: 0.096, accuracy: 0.972\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "# Epoch: 3/10\n",
            "# Training phase --------------------------------------------------\n",
            "loss: 0.079, accuracy: 0.978\n",
            "----------------------------------------------------------------------\n",
            "# Validation phase --------------------------------------------------\n",
            "loss: 0.094, accuracy: 0.974\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "# Epoch: 4/10\n",
            "# Training phase --------------------------------------------------\n",
            "loss: 0.070, accuracy: 0.980\n",
            "----------------------------------------------------------------------\n",
            "# Validation phase --------------------------------------------------\n",
            "loss: 0.062, accuracy: 0.983\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "# Epoch: 5/10\n",
            "# Training phase --------------------------------------------------\n",
            "loss: 0.065, accuracy: 0.982\n",
            "----------------------------------------------------------------------\n",
            "# Validation phase --------------------------------------------------\n",
            "loss: 0.099, accuracy: 0.976\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "# Epoch: 6/10\n",
            "# Training phase --------------------------------------------------\n",
            "loss: 0.065, accuracy: 0.983\n",
            "----------------------------------------------------------------------\n",
            "# Validation phase --------------------------------------------------\n",
            "loss: 0.061, accuracy: 0.985\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "# Epoch: 7/10\n",
            "# Training phase --------------------------------------------------\n",
            "loss: 0.061, accuracy: 0.985\n",
            "----------------------------------------------------------------------\n",
            "# Validation phase --------------------------------------------------\n",
            "loss: 0.080, accuracy: 0.982\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "# Epoch: 8/10\n",
            "# Training phase --------------------------------------------------\n",
            "loss: 0.060, accuracy: 0.985\n",
            "----------------------------------------------------------------------\n",
            "# Validation phase --------------------------------------------------\n",
            "loss: 0.104, accuracy: 0.977\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "# Epoch: 9/10\n",
            "# Training phase --------------------------------------------------\n",
            "loss: 0.065, accuracy: 0.985\n",
            "----------------------------------------------------------------------\n",
            "# Validation phase --------------------------------------------------\n",
            "loss: 0.085, accuracy: 0.983\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "# Epoch: 10/10\n",
            "# Training phase --------------------------------------------------\n",
            "loss: 0.063, accuracy: 0.985\n",
            "----------------------------------------------------------------------\n",
            "# Validation phase --------------------------------------------------\n",
            "loss: 0.097, accuracy: 0.979\n",
            "----------------------------------------------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Global Average Pooling\n",
        "\n",
        "- CNN에서 feature extractor layer에서 classifier로 넘어갈 때 2차원 feature map을 flatten하게 펼쳐 fc (fully connected) layer를 연결해요\n",
        "- 하지만 이 방식은 문제점이 있어요\n",
        "    - 1. 공간적 정보를 손실\n",
        "    - 2. 많은 수의 노드가 나와 학습해야 할 파라미터 수가 증가\n",
        "\n",
        "- 그래서 제안한 것이 GAP (Global Average Pooling)입니다\n",
        "\n",
        "<img src = \"https://www.researchgate.net/publication/343094775/figure/fig4/AS:915542533763072@1595293758149/Comparison-between-a-fully-connected-layers-in-CNNs-and-b-the-global-average-pooling.png\">\n",
        "\n",
        "- 위 그림에서 왼쪽이 fc layer, 오른쪽이 gap예요\n",
        "- 이제 fc와 gap를 각각 적용해 파라미터 수의 차이를 알아보죠"
      ],
      "metadata": {
        "id": "ZtjDL1YakgjB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# fc layer 적용한 CNN\n",
        "class FCcnn(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(FCcnn, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            # convolution layer\n",
        "            nn.Conv2d(1, 8, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(8, 16, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(7 * 7 * 16, 100),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(100, 10),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.size(0)\n",
        "        x = self.features(x)\n",
        "        x = x.view(batch_size, -1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "# GAP 적용한 CNN\n",
        "class GAPcnn(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(GAPcnn, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            # convolution layer\n",
        "            nn.Conv2d(1, 8, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(8, 16, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "\n",
        "        # global average pooling 적용\n",
        "        self.gap = nn.AdaptiveAvgPool2d(output_size=(1, 1))\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(16, 100),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(100, 10),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.size(0)\n",
        "        x = self.features(x)\n",
        "        x = self.gap(x)\n",
        "        x = x.view(batch_size, -1)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "zxULu0idM0Sd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary(FCcnn(), (1, 28, 28))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3jG203OCM0VD",
        "outputId": "74110440-067c-4caa-d84e-1f4da411439b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1            [-1, 8, 28, 28]              80\n",
            "              ReLU-2            [-1, 8, 28, 28]               0\n",
            "         MaxPool2d-3            [-1, 8, 14, 14]               0\n",
            "            Conv2d-4           [-1, 16, 14, 14]           1,168\n",
            "              ReLU-5           [-1, 16, 14, 14]               0\n",
            "         MaxPool2d-6             [-1, 16, 7, 7]               0\n",
            "            Linear-7                  [-1, 100]          78,500\n",
            "              ReLU-8                  [-1, 100]               0\n",
            "            Linear-9                   [-1, 10]           1,010\n",
            "================================================================\n",
            "Total params: 80,758\n",
            "Trainable params: 80,758\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.16\n",
            "Params size (MB): 0.31\n",
            "Estimated Total Size (MB): 0.47\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summary(GAPcnn(), (1, 28, 28))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ygOu5_c-nLUb",
        "outputId": "4fa7bdca-de78-4625-a7ff-e361efed025d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1            [-1, 8, 28, 28]              80\n",
            "              ReLU-2            [-1, 8, 28, 28]               0\n",
            "         MaxPool2d-3            [-1, 8, 14, 14]               0\n",
            "            Conv2d-4           [-1, 16, 14, 14]           1,168\n",
            "              ReLU-5           [-1, 16, 14, 14]               0\n",
            "         MaxPool2d-6             [-1, 16, 7, 7]               0\n",
            " AdaptiveAvgPool2d-7             [-1, 16, 1, 1]               0\n",
            "            Linear-8                  [-1, 100]           1,700\n",
            "              ReLU-9                  [-1, 100]               0\n",
            "           Linear-10                   [-1, 10]           1,010\n",
            "================================================================\n",
            "Total params: 3,958\n",
            "Trainable params: 3,958\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.16\n",
            "Params size (MB): 0.02\n",
            "Estimated Total Size (MB): 0.18\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Leyucn2znP39"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}